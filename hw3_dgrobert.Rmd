---
title: "dgrobert_ada_hw3"
author: "deving"
date: "4/19/2021"
output: html_document
---
```{r}
library(tidyverse)
library(ggpubr)
library(ggpmisc)
library(broom)
library(infer)
library(lmodel2)
library(manipulate)
library(patchwork)
library(infer)
library(boot)
library(car)
```

#  CHALLENGE 1:

##  Read in kamilar and cooper data
```{r}
f <- "https://raw.githubusercontent.com/difiore/ada-2021-datasets/main/KamilarAndCooperData.csv"
d <- read_csv(f, col_names = TRUE) 
```

##  fit regression model for untransformed data
```{r}
lm_1<-lm(WeaningAge_d ~ Brain_Size_Species_Mean, d)
```

##  scatterplot with fitted line and model equation
```{r}
p1 <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = WeaningAge_d), na.rm=TRUE) +
  geom_point()
p1  <- p1 + geom_smooth(method = 'lm', se= FALSE, color="black" )+
  stat_regline_equation(label.y = 1000)
p1
```

##  id and interpret point estimate of the slope, also interpret null hypothesis that slope = 0.  find 90% CI for the slope
```{r}
summary.lm(lm_1)
```

##  slope is 2.627, very low p value leads us to reject the null.  The 90% CI for the slope is the range between slopes estimate plus 1.96*SE and slope estimate minus 1.96*SE: 
```{r}
upper<-2.6371+1.96*0.1847
lower<-2.6371-1.96*0.1847
upper  
```

##  2.999112
```{r}
lower
```
##  2.275088

##  add 90% CI & PI lines, include legend
```{r}
ci<- predict(lm_1,
  newdata = data.frame(Brain_Size_Species_Mean=d$Brain_Size_Species_Mean),
  interval = "confidence", level = 0.9
)
ci<-data.frame(ci)
ci<-cbind(d$Brain_Size_Species_Mean, ci)
names(ci) <- c("brain", "c.fit", "c.lwr", "c.upr")
p1 <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = WeaningAge_d), na.rm=TRUE)
p1 <- p1 + geom_point(alpha=0.5)
p1 <- p1 + geom_line(
  data = ci, aes(x = brain, y=c.fit,
  color = "FIT LINE"))
p1 <- p1 + geom_line(
  data=ci, aes(x=brain, y=c.lwr,
  color="CI"))
p1 <- p1 + geom_line(
  data=ci, aes(x=brain, y=c.upr, color="CI"))
p1
pi<- predict(lm_1,
  newdata = data.frame(Brain_Size_Species_Mean=d$Brain_Size_Species_Mean),
  interval = "prediction", level = 0.9
)
pi <- data.frame(pi)
pi <- cbind(d$Brain_Size_Species_Mean, pi)
names(pi) <-c("brain", "p.fit", "p.lwr", "p.upr")

p1 <- p1 + geom_line(data = pi, aes(x = brain, y = p.lwr, color = "PI"))
p1 <- p1 + geom_line(data = pi, aes(x = brain, y = p.upr, color = "PI"))
p1 <- p1 + scale_color_manual(values=c("blue", "black", "red"))
p1
```
##  point estimate and 90% PI for brain weight of 750
```{r}
point <- predict(lm_1,
  newdata = data.frame(Brain_Size_Species_Mean = 750),
  interval = "confidence", level = 0.9
) 
point
```
##  the point estimate and prediction interval are unreliable for this value of the predictor because it is far higher than the observed range of mean brain size values

##  do all that over but with log transformed data
```{r}
d$Brain_Size_Species_Mean<-(log(d$Brain_Size_Species_Mean))
d$WeaningAge_d<-(log(d$WeaningAge_d))

lm_2<-lm(WeaningAge_d ~ Brain_Size_Species_Mean, d)
```

##  id and interpret point estimate of the slope, also interpret null hypothesis that slope = 0.  find 90% CI for the slope
```{r}
summary.lm(lm_2)
```
##  p value is very small so the null is rejected.  slope of log transformed data is 0.57
```{r}
upper<- 0.57116+1.96*0.03061
lower<- 0.57116-1.96*0.03061
upper
```

##  0.6311556
```{r}
lower
```
##  0.5111644

##  create plot with log transformed data and CI, PI, Fit line, and legend
```{r}
ci<- predict(lm_2,
  newdata = data.frame(Brain_Size_Species_Mean=d$Brain_Size_Species_Mean),
  interval = "confidence", level = 0.9
)
ci<-data.frame(ci)
ci<-cbind(d$Brain_Size_Species_Mean, ci)
names(ci) <- c("brain", "c.fit", "c.lwr", "c.upr")
p2 <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = WeaningAge_d), na.rm=TRUE)
p2 <- p2 + geom_point(alpha=0.5)
p2 <- p2 + geom_line(
  data = ci, aes(x = brain, y=c.fit,
  color = "FIT LINE"))
p2 <- p2 + geom_line(
  data=ci, aes(x=brain, y=c.lwr,
  color="CI"))
p2 <- p2 + geom_line(
  data=ci, aes(x=brain, y=c.upr, color="CI"))
p2 <- p2 + scale_y_continuous(trans='log10')
p2 <- p2 + scale_x_continuous(trans='log10')
p2
pi<- predict(lm_2,
  newdata = data.frame(Brain_Size_Species_Mean=d$Brain_Size_Species_Mean),
  interval = "prediction", level = 0.9
)
pi <- data.frame(pi)
pi <- cbind(d$Brain_Size_Species_Mean, pi)
names(pi) <-c("brain", "p.fit", "p.lwr", "p.upr")

p2 <- p2 + geom_line(data = pi, aes(x = brain, y = p.lwr, color = "PI"))
p2 <- p2 + geom_line(data = pi, aes(x = brain, y = p.upr, color = "PI"))
p2 <- p2 + scale_color_manual(values=c("blue", "black", "red"))
p2
```

##  change "windows" to "quartz" on a mac if you want to see untransformed and transformed in separate windows
```{r}
windows()
p1
windows()
p2
```

##  the log transformed version seems to capture the relationship between the variables much better, indicating that the relationship is geometric (constant ratio between terms) and not arithmetic (constant difference between terms).  This is very often the case in biology and ecology, which limits intuitive understanding and probably is because we sample in fewer dimensions than the underlying biological driver, e.g. height is a linear proxy for a physical phenomena that occurs in 3 dimensions, similar but interestingly distinct examples from from reproduction and scaling corrections for population demographic data. The red flag in this case is the point cluster that falls outside the PI with brain size around 100 (untransformed version).  That point cluster fits pretty nicely in the transformed version.

#  CHALLENGE #2
##  re-read in kamilar and cooper data bc the challenge 1 version has been rendered unpure
```{r}
f <- "https://raw.githubusercontent.com/difiore/ada-2021-datasets/main/KamilarAndCooperData.csv"
d <- read_csv(f, col_names = TRUE) 
```

##  run reg on log transformed group size and log female body mass, report beta coefs
##  remove missing values
```{r}
d=na.omit(d)
```
##  log transform
```{r}
d$log_gs<-log(d$MeanGroupSize)
d$log_fbm<-log(d$Body_mass_female_mean)
```
##  create linear model object
```{r}
lm_1<-lm(log_gs ~ log_fbm, data=d)
summary(lm_1)
```
##  intercept: 1.14, slope: 0.15

##  generate bootstrap sampling dist and plot histo for each beta coef
##  intercept
```{r}
boot.coefs <- Boot(lm_1, f=coef, R=1000) 

hist(boot.coefs)
```

##  estimate standard error
```{r}
summary(boot.coefs)
```

##  intercept SE= 1.61, slope SE=0.19

##  determine 95% confidence intervals of beta coefs
```{r}
confint(boot.coefs, level=0.95, type="norm")
```
##  intercept: -1.96 to 4.35, slope: -0.23 to 0.52

##  the SEs estimated from bootstrap sampling distribution are a little higher than from the original linear model

##  compare boot strap CIs to lm CIs
```{r}
confint(lm_1, level=0.95, type="norm")
```
##  the CIs from bootstrap are larger, but not as much as I might have expected.  pretty similar.

#  CHALLENGE 3
##  write your own function called boot-lm...etc

##  set up a generic bootstrapping function
```{r}
  boot_lm <- function(d, model, reps) {
  
  original.est <- get(model)(d)
  
  n_est <- length(original.est)

  temp <- matrix(NA, ncol = n_est , nrow = reps)

  nobs <- nrow(d)

  for (i in 1:reps) {
    posdraws <- ceiling(runif(nobs)*nobs)
    draw <- d[posdraws,]
    temp[i,] <- get(model)(draw)
  }

  sds <- apply(temp,2,sd)
  CI <- apply(temp, 2, quantile, probs = c(0.025, 0.975))
  print(rbind(original.est, sds, CI))
  return(list(estimates=temp, sds=sds))
}
```
##  here is the first model, female body mass predicts group size
```{r}

gs_fbm <- function(d) lm(d$log_gs ~ d$log_fbm)[[1]]

gs_fbm.res<-boot_lm(d, "gs_fbm", reps=1000)
```

##  creating a log transform of day length variable
```{r}
d$log_dl<-log(d$DayLength_km)
```

##  female body mass predicts day length
```{r}
dl_fbm <- function(d) lm(d$log_dl ~ d$log_fbm)[[1]]

dl_fbm.res<-boot_lm(d, "dl_fbm", reps=1000)
```
##  female body mass and group size predict day length
```{r}
dl_fbm_gs <- function(d) lm((d$log_dl) ~ (d$log_fbm) + (d$log_gs))[[1]]

dl_fbm_gs.res<-boot_lm(d, "dl_fbm", reps=1000)
```
##  versions where bootstrapping and lm() were combined into a single function were buggy, I could not make it work after several attemps.  This version, where you first define the model and then apply bootstrap simulation, is more versatile anyway